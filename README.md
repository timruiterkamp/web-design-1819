# Web Design @cmda-minor-web 1819

Making a usable product for Marie, who has been deaf from her birth. In these weeks I am going to create a talk show video provided by great closed captions that will be great to read for Marie.

## Week 1

![]('gh-images/week1.png/');
In the first week, it was mostly looking at examples and what is possible with different technologies. There are multiple options, you could add a VTT file to the HTML5 video or implement text directly in the video with something like premiere pro.

The closed captions are quite limited, you can change the positions, default font sizes, background color of the text and font families. But with premiere pro or after effects you could create more meaningful experiences like create bounces on the way people knock on the door. This would eventually take a lot more work but also provides the video with meaningful experiences.

### Evaluation

The first time we met Marie, I was intrigued by the way she and her translator communicate. They are very swiftly with their hands and the translator is really good at giving nonsense that we were providing meaning and let us get meaningful feedback from Marie.
The test that I did was to locate noises on the screen so that if someone on the left would talk, the text will also appear at their current location. It was a fun little experiment, but she admitted that it could get annoying when you're using without the right reasons.

### Feedback Friday

At Friday I was a bit stuck in the closed caption situation and wasn't fond of the limits that closed captions give you. After giving my opinion to Vasilis, he gave me some great insights like get away from closed captions and use HTML, CSS, and JS to add text and more overall experience to the video.

## Week 2

![]('gh-images/week2.png/');

At Monday I directly started with looking at a different solution to locate noises that take place inside the video. I eventually came up with a glowing indicator that transforms from position to position based on where the noise is coming from. I added custom interactions based on background noise like the screen will shake if the school bell rings for example.

### Evaluation

The evaluation of my product till this stage went overall quite well. However, I could've created more simple examples with maybe minimal or no layout at all to test more possible features.

The main thing I wanted to know was if the noise direction indicator was the right addition to a movie. While testing Marie said that it really was interesting, as normally she can't locate the noise or give meaning to noise. This breaks the feeling that a certain scene should give, and for me to make it possible for Marie to get more feeling by a scene without music, would be a very good accomplishment.

Other notices were that she really likes to know at what speed someone talks and this would be very helpful to her to get grip on the talking setting (How the conversation flow is going).

## Week 3

![]('gh-images/week3.png/');
This week was about creating a final version for Marie containing the feedback points from last week. I focused on giving more meaning to the location of sound by displaying emotions in the form of color at the place where the sound comes from.

The questions I wanted an answer on were all based on the color indication. I asked Marie if the 'wheel of emotions' by Plutchik's was any help. And the answer I got to that was that it could be a great addition but she should learn the colors before watching the movie.

The second thing I asked was if she wanted to only have offscreen sounds highlighted or every emotion of a person. To this question she didn't really have a clear answer because she would have to see how the movie can be experienced when all the emotions are mapped.

Based on this feedback I will create a part of the movie with all emotions mapped for my final product. With this I want to create a proof of concept that a movie can be way more exciting for people that are deaf by showing emotions and the location / direction of sounds.

### Short explanation to the Plutchik's wheel of emotion

Because of that Marie is deaf, she has never heard what sound goes by what emotion / color. I wanted to create a way that she can reconize someone's emotion by giving a meaning to a color. To do this, I used the Pluctchik's wheen of emotion. Robert Plutchik is a psychologist who created a theory of emotion, the wheel illustrates the relationships between primary and other related emotions.

The basic emotions are:

- Red: Anger, to fight against problems
- Green: Fear, to protect from danger
- Orange: Anticipation, to look forward and plan
- Light blue: Surprise, to focus on new situations
- Yellow: Joy, To remind us what's important
- Blue: Sadness, To connect us with the ones we love
- Light green: Trust, to connect with people who help
- Purple: Disgust, to reject what is unhealthy

Based on this wheel I picked my assigning colors to emotions in my project.
